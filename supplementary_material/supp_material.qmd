---
title: " Levelling up: How to unlock ecological and evolutionary data with hierarchical - Supplementary Material "
author: 
  - name: Camille Lévesque
    affiliation: Université Laval
    email: camille.levesque.7@ulaval.ca
  - name: Katherine Hébert
    affiliation: McGill University
    email: katherine.hebert@mcgill.ca
  - name: Laurence Feyten
    affiliation: Université du Québec à Montréal
    email: laurencefeyten@mac.com
  - name: Isabelle Lebeuf-Taylor
    affiliation: University of Alberta
    email: lebeufta@ualberta.ca
  - name: Kim Ménard
    affiliation: Université TÉLUQ
    email: kim.menard.2@ulaval.ca
  - name: Pedro Henrique Pereira Braga
    affiliation: McGill University
    email: pedro.pereirabraga@mcgill.ca
  - name: Alejandro Sepúlveda-Correa
    affiliation: Université du Québec en Outaouais
    email: sepa01@uqo.ca
  - name: Aliénor Stahl
    affiliation: Université du Québec à Trois-Rivières
    email: alienor.stahl@uqtr.ca
  - name: Lukas Van Riel
    affiliation: Université de Montréal
    email: lukas.van.riel@umontreal.ca

date: "2025-11-07"
format:
  html:
    toc: true
    number-sections: true
    embed-resources: true
editor: visual
---

# Overview

This document contains the detailed code and supplementary materials for the article *“Levelling up: How to unlock ecological data with hierarchical generalized additive models.”*

In the article, coding examples are organized into three thematic boxes, each corresponding to a main section: **(1)** *Estimating a hierarchy of trends* (Trends), **(2)** *Unpacking meaningful variance and covariances from noisy biological data* (Variance), and **(3)** *Borrowing strength to boost predictions* (Prediction). Most of the code presented here builds upon the examples and model structures introduced in Pedersen et al. (2019).

# Data

We use the North American Breeding Bird Survey dataset extracted from [BioTIME](https://biotime.st-andrews.ac.uk/selectStudy.php?study=195) (Pardieck et al., 2015), a long-term monitoring program of North American bird populations that began in 1966. Our analyses focus on a subset of the data collected near Waverly, New York (44.55, -74.4833) between 1978 and 2007, which includes 36 bird species. Table 1 presents the species used in the different coding examples (Boxes), which differ from a box to another because of the objectives/needs of the examples.

**Table S1:** Bird species and their inclusion (indicated with tick marks) in examples presented in Boxes 1, 2, and 3. These 36 species represent a randomly-selected subset of the North American Breeding Bird Survey dataset as curated in BioTIME (Pardieck et al., 2015; Dornelas et al. 2018), corresponding to data from Waverly, New York (latitude 44.55, and longitude -74.4833) collected between 1978 and 2007. For Boxes 2 and 3, we sub-selected from the 36 species to showcase the top most common species.

|                              |                          |       | **Box** |       |
|----------------|--------------|:------------:|:------------:|:------------:|
| Common name                  | Species name             | **1** |  **2**  | **3** |
| Red-winged blackbird         | *Agelaius phoeniceus*    |   x   |    x    |   x   |
| Northern cardinal            | *Cardinalis cardinalis*  |   x   |         |       |
| Hermit thrush                | *Chaetura pelagica*      |       |    x    |   x   |
| Chimney swift                | *Chaetura pelagica*      |   x   |         |       |
| Northern flicker             | *Colaptes auratus*       |   x   |         |       |
| Rock pigeon                  | *Columba livia*          |   x   |         |       |
| Eastern wood-pewee           | *Contopus virens*        |   x   |         |       |
| American crow                | *Corvus brachyrhynchos*  |   x   |         |       |
| Blue jay                     | *Cyanocitta cristata*    |   x   |         |       |
| Downy woodpecker             | *Dryobates pubescens*    |   x   |         |       |
| Gray catbird                 | *Dumetella carolinensis* |   x   |         |       |
| Common yellowthroat          | *Geothlypis trichas*     |   x   |         |       |
| Barn swallow                 | *Hirundo rustica*        |   x   |         |       |
| Song sparrow                 | *Melospiza melodia*      |   x   |    x    |   x   |
| Black-and-white warbler      | *Mniotilta varia*        |       |    x    |   x   |
| Brown-headed cowbird         | *Molothrus ater*         |   x   |         |       |
| Great crested flycatcher     | *Myiarchus crinitus*     |   x   |         |       |
| House sparrow                | *Passer domesticus*      |   x   |         |       |
| Indigo bunting               | *Passerina cyanea*       |   x   |         |       |
| Common grackle               | *Quiscalus quiscula*     |   x   |         |       |
| Eastern phoebe               | *Sayornis phoebe*        |   x   |         |       |
| Ovenbird                     | *Seiurus aurocapilla*    |       |    x    |   x   |
| Yellow-rumped warbler        | *Setophaga coronata*     |       |    x    |   x   |
| Black-throated green warbler | *Setophaga virens*       |       |    x    |   x   |
| American goldfinch           | *Spinus tristis*         |   x   |    x    |   x   |
| Chipping sparrow             | *Spizella passerina*     |   x   |         |       |
| Field sparrow                | *Spizella pusilla*       |   x   |         |       |
| Eastern meadowlark           | *Sturnella magna*        |   x   |         |       |
| Common starling              | *Sturnus vulgaris*       |   x   |         |       |
| Brown trasher                | *Toxostoma rufum*        |   x   |         |       |
| Northern house wren          | *Troglodytes aedon*      |   x   |         |       |
| American robin               | *Turdus migratorius*     |   x   |    x    |   x   |
| Eastern kingbird             | *Tyrannus tyrannus*      |   x   |         |       |
| Red-eyed vireo               | *Vireo olivaceus*        |   x   |         |       |
| Blue-headed vireo            | *Vireo solitarius*       |       |    x    |   x   |
| Mourning dove                | *Zenaida macroura*       |   x   |         |       |

# Coding examples

## Setting up the work environment

### Packages and Libraries

Here, we install and load the packages required for the coding examples.

```{r,message=FALSE,warning=FALSE,results='hide'}
# install.packages("pacman")

pacman::p_load(mgcv, # For fitting Generalized Additive Models (GAMs) and Hierarchical GAMs
dplyr,           # For data manipulation 
ggplot2,         # For data visualization
tidyr,           # For reshaping and tidying data
mvtnorm,         # For working with multivariate normal and t-distributions
gratia,          # For visualizing and interpreting GAMs fitted with mgcv
here,            # For handling file paths relative to the project root
gridExtra,       # For arranging multiple ggplot2 plots into grids
mvgam,           # For fitting multivariate/State-Space GAMs and plotting model components
marginaleffects, # For obtaining marginal/average predictions from fitted models
tidyverse,       # For the full suite of tidy tools (read, wrangle, plot) in one load
cmdstanr)        # For fitting Stan models via CmdStan, backend for mvgam
```

### Import and clean the data

We import the raw BBS data downloaded from BioTIME.

```{r}
setwd(here::here())
df = read.csv("data/raw/raw_data_195.csv")
```

We filter and clean the data according to our needs, then we save the dataset.

```{r}

# Filter to years in common across many species
df_years = df |>
  group_by(valid_name) |>
  summarise("min_year" = min(YEAR),
            "max_year" = max(YEAR))
# Look for the most common minimum and maximum years
df_years$min_year |> table()
df_years$max_year |> table()

# 309 species to keep
sp_to_keep = df_years |> filter(min_year == 1978, max_year == 2007)

# Cut to species that have data between 1978 and 2007
df = df |> filter(valid_name %in% sp_to_keep$valid_name)

# Save this dataset
# write.csv(df, "data/clean/data_195.csv", row.names = FALSE)
```

We crop the dataset to keep data from the region of Waverly, New York.

```{r}
df = df |>
  select(-c(SAMPLE_DESC, DAY, MONTH, BIOMAS))

sites = paste0(df$LONGITUDE,"_", df$LATITUDE)
table(sites)

# crop to a site
d_crop = df[sites %in% "-74.4833_44.55",] # We keep sites in Waverly, New York
```

## Box 1 - Trends

HGAMs offer an indicator-based approach using nonparametric spatiotemporal regression models to identify periods of change in community abundance or composition (i.e., regime shifts). This method estimates three key indicators: 1) the mean rate of change across all species, 2) the mean per-capita rate of change, and 3) the standard deviation of per-capita rates of change (Pedersen et al., 2020).

1.  **The mean rate of change across all species**

    This indicator represents the average temporal rate of change in abundance across all species in the community. It provides a general measure of whether the community as a whole is increasing or decreasing in total abundance over time.

2.  **The mean per-capita rate of change**

    This indicator expresses the average rate of change per individual, capturing the community’s relative growth or decline independently of overall abundance. It is analogous to the population growth rate at the individual level and reflects how efficiently individuals contribute to population change through time.

3.  **The standard deviation of per-capita rates of change**

    This indicator quantifies the variability in per-capita rates of change among species. High values suggest that species respond differently to environmental or ecological drivers, indicating potential desynchronization or restructuring within the community, which can signal the onset of regime shifts.

### Step 1: Process the data

We process the data by selecting the 30 most abundant species for the analyses.

```{r}
# Aggregating biomass data to get a yearly abundance for each species.
community_ts <- d_crop %>%
  filter(!is.na(YEAR) & !is.na(valid_name) & valid_name != "") %>%
  group_by(YEAR, valid_name) %>%
  summarise(ABUNDANCE = n(), .groups = 'drop') %>%
  rename(year = YEAR, species = valid_name, abundance = ABUNDANCE)

# Selecting the top 30 most frequently observed species (i.e., highest in abundance)
top_species <- community_ts %>% # Identify the top 30 species
  group_by(species) %>%
  summarise(total_abundance = sum(abundance)) %>%
  arrange(desc(total_abundance)) %>%
  slice_head(n = 30) %>%
  pull(species)

community_ts_subset <- community_ts %>% # Create a new table with only the top 30 species
  filter(species %in% top_species) %>%
  mutate(species = as.factor(species))

head(community_ts_subset) # The subset of data that we will use from this point on in this section (Box 1)
```

### Step 2: Fit Model GS (poisson)

Here, we fit the “GS” model described in Pedersen et al. (2019). Since the response variable represents abundance (count) data, we use the Poisson family.

```{r}
# MODEL: The 'GS' Model (Global smooth + species-specific deviations)
gam_model_GS <- gam(
  # Global relationship
  abundance ~ s(year, bs = "tp") + 
    
  # Species-specific smoother: a factor-smoother interaction of year and species
  s(year, by = species, bs = "fs") + 
    
  # Species as random effects (gives an intercept per species)
  s(species, bs="re"), 
  
  # Data
  data = community_ts_subset,
  
  # Distribution family: Poisson for count data
  family = poisson(), 
  
  # Estimating smoothing parameters using restricted maximum likelihood (REML)
  method = "REML"
)
```

### Step 3: Derivatives and Indicators

In this section, we generate predictions and calculate community-level indicators from the fitted **GS model**. We first create a prediction dataset covering all species and years, and use a small value (*ε*) to approximate derivatives numerically. We then draw 250 posterior simulations from the model coefficients to account for parameter uncertainty. Using these simulations, we compute predicted abundances and their first derivatives, which are used to estimate per capita rates of change. Finally, we summarize these results to obtain three community indicators for each year: the mean rate of change, the mean per capita rate of change, and the standard deviation of per capita rates of change, along with their median and 95% confidence intervals.

```{r}
# Create a prediction dataset
predict_data <- community_ts_subset %>%
  select(year, species) %>%
  distinct()

# Define a small number 'eps' for numerical differentiation
eps <- 1e-7 # Define a small number epsilon ε 'eps'
predict_data_p_eps <- predict_data %>% mutate(year = year + eps)
predict_data_m_eps <- predict_data %>% mutate(year = year - eps)

# Generate posterior simulations from the GS model
n_sim <- 250
set.seed(42)
sim_lp_GS <- predict(gam_model_GS, newdata = predict_data, type = "lpmatrix")
sim_coef_GS <- rmvnorm(n_sim, coef(gam_model_GS), vcov(gam_model_GS, unconditional = TRUE))

# Calculate predicted values and derivatives for the GS model
pred_original_GS <- exp(sim_lp_GS %*% t(sim_coef_GS))
pred_p_eps_GS <- exp(predict(gam_model_GS, newdata = predict_data_p_eps, type = "lpmatrix") %*% t(sim_coef_GS))
pred_m_eps_GS <- exp(predict(gam_model_GS, newdata = predict_data_m_eps, type = "lpmatrix") %*% t(sim_coef_GS))
first_derivative_GS <- (pred_p_eps_GS - pred_m_eps_GS) / (2 * eps)
per_capita_rate_GS <- first_derivative_GS / (pred_original_GS + 1e-9)

# Reshape simulation results for the GS model
sim_deriv_long_GS <- as.data.frame(first_derivative_GS) %>%
  mutate(row = 1:n()) %>%
  pivot_longer(-row, names_to = "sim_id", values_to = "derivative")
sim_per_capita_long_GS <- as.data.frame(per_capita_rate_GS) %>%
  mutate(row = 1:n()) %>%
  pivot_longer(-row, names_to = "sim_id", values_to = "per_capita_rate")

sim_results_GS <- predict_data %>%
  mutate(row = 1:n()) %>%
  left_join(sim_deriv_long_GS, by = "row") %>%
  left_join(sim_per_capita_long_GS, by = c("row", "sim_id"))

# Calculate community indicators for the GS model
community_indicators_GS <- sim_results_GS %>%
  group_by(year, sim_id) %>%
  summarise(
    mean_rate_of_change = mean(derivative, na.rm = TRUE),
    mean_per_capita_rate = mean(per_capita_rate, na.rm = TRUE),
    sd_per_capita_rate = sd(per_capita_rate, na.rm = TRUE),
    .groups = 'drop'
  )

# Final summary of indicators for the GS model
final_indicators_GS <- community_indicators_GS %>%
  group_by(year) %>%
  summarise(
    across(
      .cols = c(mean_rate_of_change, mean_per_capita_rate, sd_per_capita_rate),
      .fns = list(
        median = ~median(.x, na.rm = TRUE),
        lower_ci = ~quantile(.x, 0.025, na.rm = TRUE),
        upper_ci = ~quantile(.x, 0.975, na.rm = TRUE)
      ),
      .names = "{.col}_{.fn}"
    ),
    .groups = 'drop'
  ) %>%
  mutate(model_type = "GS Model") # Add a label for plotting

```

#### Indicators from model GS

```{r}
(head(final_indicators_GS))
```

### Step 4: Plot the indicators

Here, we plot the three derivative-based indicators (mean rate of change, mean per capita rate, and the standard deviation of per capita rates) across years.

```{r}
# Plot 1: Mean Rate of Change 
plot1_mean_rof <- ggplot(final_indicators_GS, 
                         aes(x = year)) +
  geom_ribbon(aes(ymin = mean_rate_of_change_lower_ci, 
                  ymax = mean_rate_of_change_upper_ci), 
              alpha = 0.8, fill = "#8fbcbb") +
  geom_line(aes(y = mean_rate_of_change_median), linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "",
    y = "Mean rate of change\n(Abundance / Year)", x = "Year",
  ) + 
  ggpubr::theme_pubr() +
  theme(panel.grid.major = element_line(linewidth = .3))

# Plot 2: Mean Per-Capita Rate of Change 
plot2_mean_percap_rof <- ggplot(final_indicators_GS, 
                                aes(x = year)) +
  geom_ribbon(aes(ymin = mean_per_capita_rate_lower_ci, 
                  ymax = mean_per_capita_rate_upper_ci), 
              alpha = 0.8, fill = "#88c0d0") +
  geom_line(aes(y = mean_per_capita_rate_median), linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "",
    y = "Mean per-capita\nrate of change", x = "Year",
  ) + 
  ggpubr::theme_pubr() +
  theme(panel.grid.major = element_line(linewidth = .3))

# Plot 3: SD of Per-Capita Rates 
plot3_SD_percap_rof <- ggplot(final_indicators_GS, 
                              aes(x = year)) +
  geom_ribbon(aes(ymin = sd_per_capita_rate_lower_ci, 
                  ymax = sd_per_capita_rate_upper_ci), 
              alpha = 0.6, fill = "#5e81ac") +
  geom_line(aes(y = sd_per_capita_rate_median), linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "",
    y = "SD of per-capita\nrates of change", x = "Year",
  ) + 
  ggpubr::theme_pubr()+
  theme(panel.grid.major = element_line(linewidth = .3))

# Print the plots
print(plot1_mean_rof)
print(plot2_mean_percap_rof)
print(plot3_SD_percap_rof)
```

### Step 5: Making a figure with the plots of indicators

Here, we create the figure that displays the three derivative-based indicators. This figure corresponds to **Box 1** in the paper (i.e., **Figure 3**).

```{r}
library(patchwork)
plot1_mean_rof + plot2_mean_percap_rof + plot3_SD_percap_rof + plot_annotation(tag_levels = "a")
ggsave(paste0(here::here(), "/trends/figures/trends_indicators_plots.png"),
       width = 10.3, height = 3.24)
```

### Additional material from the "Trends" section

Here, we present additional code developed for the *Trends* section of the paper, which was not used directly in the final version of the manuscript.

#### Plotting the species-specific trends from the GS Model

Here, we plot the species-specific trends estimated from the GS model.

```{r}
# Get predictions from the GS model
preds_GS <- predict(gam_model_GS, newdata = predict_data, type = "response", se.fit = TRUE)
plot_data_GS <- predict_data %>%
  mutate(
    fit = preds_GS$fit,
    se = preds_GS$se.fit,
    lower_ci = fit - 1.96 * se,
    upper_ci = fit + 1.96 * se
  ) %>%
  left_join(community_ts_subset, by = c("year", "species"))

# Plot trends from GS model
species_trends_plot_GS <- ggplot(plot_data_GS, aes(x = year)) +
  geom_point(aes(y = abundance), color = "grey60", alpha = 0.8) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), fill = "darkorange", alpha = 0.3) +
  geom_line(aes(y = fit), color = "darkorange", size = 1) +
  facet_wrap(~ species, scales = "free_y") +
  labs(
    title = "Fitted Abundance Trends for Each Species (GS Model)",
    y = "Predicted Abundance", x = "Year"
  ) +
  theme_minimal()

print(species_trends_plot_GS)
```

#### Fitting Model "S" and comparing with Model "GS"

Before selecting the **GS model** as the main example in the Box 1 of the article, we also fitted the **S model** (Pedersen et al., 2019) and compared the performance of the two models.\

The code used for this comparison is provided below.

##### Step 1: Fit Model "S" (poisson)

Here, we fit the model using the same data subset that was previously used for the GS model. Since the response variable represents abundance (count) data, we use the Poisson family.

```{r}
# The 'S' Model (Separate smooths for each species)
gam_model_S <- gam(
  abundance ~ species +
  s(year, by = species, bs = "fs") + # Species-specific smoother: a factor-smoother interaction of year and species
  s(species, bs = "re"), # Species as random effects (gives an intercept per species)
  data = community_ts_subset,
  family = poisson(), # Using Poisson family
  method = "REML"
)
```

##### Step 2: Derivatives and Indicators (model S)

In this section, we generate predictions and calculate community-level indicators from the fitted **S model**. We first create a prediction dataset covering all species and years, and use a small value (*ε*) to approximate derivatives numerically. We then draw 250 posterior simulations from the model coefficients to account for parameter uncertainty. Using these simulations, we compute predicted abundances and their first derivatives, which are used to estimate per capita rates of change. Finally, we summarize these results to obtain three community indicators for each year: the mean rate of change, the mean per capita rate of change, and the standard deviation of per capita rates of change, along with their median and 95% confidence intervals.

```{r}
# Create a prediction dataset
predict_data <- community_ts_subset %>%
  select(year, species) %>%
  distinct()

# Define a small number 'eps' for numerical differentiation
eps <- 1e-7
predict_data_p_eps <- predict_data %>% mutate(year = year + eps)
predict_data_m_eps <- predict_data %>% mutate(year = year - eps)

# Generate posterior simulations from the S model
n_sim <- 250
set.seed(42)
sim_lp_S <- predict(gam_model_S, newdata = predict_data, type = "lpmatrix")
sim_coef_S <- rmvnorm(n_sim, coef(gam_model_S), vcov(gam_model_S, unconditional = TRUE))

# Calculate predicted values and derivatives for the S model
pred_original_S <- exp(sim_lp_S %*% t(sim_coef_S))
pred_p_eps_S <- exp(predict(gam_model_S, newdata = predict_data_p_eps, type = "lpmatrix") %*% t(sim_coef_S))
pred_m_eps_S <- exp(predict(gam_model_S, newdata = predict_data_m_eps, type = "lpmatrix") %*% t(sim_coef_S))
first_derivative_S <- (pred_p_eps_S - pred_m_eps_S) / (2 * eps)
per_capita_rate_S <- first_derivative_S / (pred_original_S + 1e-9)

# Reshape simulation results for the S model
sim_deriv_long_S <- as.data.frame(first_derivative_S) %>%
  mutate(row = 1:n()) %>%
  pivot_longer(-row, names_to = "sim_id", values_to = "derivative")
sim_per_capita_long_S <- as.data.frame(per_capita_rate_S) %>%
  mutate(row = 1:n()) %>%
  pivot_longer(-row, names_to = "sim_id", values_to = "per_capita_rate")

sim_results_S <- predict_data %>%
  mutate(row = 1:n()) %>%
  left_join(sim_deriv_long_S, by = "row") %>%
  left_join(sim_per_capita_long_S, by = c("row", "sim_id"))

# Calculate community indicators for the S model
community_indicators_S <- sim_results_S %>%
  group_by(year, sim_id) %>%
  summarise(
    mean_rate_of_change = mean(derivative, na.rm = TRUE),
    mean_per_capita_rate = mean(per_capita_rate, na.rm = TRUE),
    sd_per_capita_rate = sd(per_capita_rate, na.rm = TRUE),
    .groups = 'drop'
  )

# Final summary of indicators for the S model
final_indicators_S <- community_indicators_S %>%
  group_by(year) %>%
  summarise(
    across(
      .cols = c(mean_rate_of_change, mean_per_capita_rate, sd_per_capita_rate),
      .fns = list(
        median = ~median(.x, na.rm = TRUE),
        lower_ci = ~quantile(.x, 0.025, na.rm = TRUE),
        upper_ci = ~quantile(.x, 0.975, na.rm = TRUE)
      ),
      .names = "{.col}_{.fn}"
    ),
    .groups = 'drop'
  ) %>%
  mutate(model_type = "S Model") # Add a label for plotting

```

###### Indicators from model S

```{r}
print(head(final_indicators_S))
```

##### Step 3: Plot and compare indicators from both models

Here, we compare each of the three derivative-based indicators obtained from the GS and S models.

```{r}
# Combine the indicator results from both models into one dataframe
combined_indicators <- bind_rows(final_indicators_S, final_indicators_GS)

# Plot 1: Mean Rate of Change Comparison
plot1_compare <- ggplot(combined_indicators, aes(x = year, group = model_type)) +
  geom_ribbon(aes(ymin = mean_rate_of_change_lower_ci, ymax = mean_rate_of_change_upper_ci, fill = model_type), alpha = 0.2) +
  geom_line(aes(y = mean_rate_of_change_median, color = model_type), linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Comparison: Mean Rate of Change",
    y = "Mean Rate of Change (Abundance / Year)", x = "Year",
    color = "Model Type", fill = "Model Type"
  ) +
  theme_minimal()

# Plot 2: Mean Per-Capita Rate of Change Comparison
plot2_compare <- ggplot(combined_indicators, aes(x = year, group = model_type)) +
  geom_ribbon(aes(ymin = mean_per_capita_rate_lower_ci, ymax = mean_per_capita_rate_upper_ci, fill = model_type), alpha = 0.2) +
  geom_line(aes(y = mean_per_capita_rate_median, color = model_type), size = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Comparison: Mean Per-Capita Rate of Change",
    y = "Mean Per-Capita Rate (Year⁻¹)", x = "Year",
    color = "Model Type", fill = "Model Type"
  ) +
  theme_minimal()

# Plot 3: SD of Per-Capita Rates Comparison
plot3_compare <- ggplot(combined_indicators, aes(x = year, group = model_type)) +
  geom_ribbon(aes(ymin = sd_per_capita_rate_lower_ci, ymax = sd_per_capita_rate_upper_ci, fill = model_type), alpha = 0.2) +
  geom_line(aes(y = sd_per_capita_rate_median, color = model_type), size = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Comparison: SD of Per-Capita Rates of Change",
    y = "SD of Per-Capita Rates (Year⁻¹)", x = "Year",
    color = "Model Type", fill = "Model Type"
  ) +
  theme_minimal()

# Print the comparison plots
print(plot1_compare)
print(plot2_compare)
print(plot3_compare)
```

##### Step 4: Comparing the models (AIC)

Here, we compare the GS and S models using the Akaike Information Criterion (AIC).

```{r}
# Compare the models using AIC
aic_S <- AIC(gam_model_S)
aic_GS <- AIC(gam_model_GS)

# Print the results for comparison
print(paste("AIC for Poisson S Model:", round(aic_S, 2)))
print(paste("AIC for Poisson GS Model:", round(aic_GS, 2)))
  # Best AIC score: Model GS
```

##### Step 5 (additional step): Plotting the species-specific trends from model S

Here, we plot the species-specific trends estimated from the S model.

```{r}
# Get predictions from the S model
preds_S <- predict(gam_model_S, newdata = predict_data, type = "response", se.fit = TRUE)
plot_data_S <- predict_data %>%
  mutate(
    fit = preds_S$fit,
    se = preds_S$se.fit,
    lower_ci = fit - 1.96 * se,
    upper_ci = fit + 1.96 * se
  ) %>%
  left_join(community_ts_subset, by = c("year", "species"))

# Plot trends from S model
species_trends_plot_S <- ggplot(plot_data_S, aes(x = year)) +
  geom_point(aes(y = abundance), color = "grey60", alpha = 0.8) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), fill = "steelblue", alpha = 0.3) +
  geom_line(aes(y = fit), color = "steelblue", size = 1) +
  facet_wrap(~ species, scales = "free_y") +
  labs(
    title = "Fitted Abundance Trends for Each Species (S Model)",
    y = "Predicted Abundance", x = "Year"
  ) +
  theme_minimal()

print(species_trends_plot_S)
```

## Box 2 - Variance

### Step 1: Process the data

We process the data for the coding example of Box 2, using the pre-processed dataset "d_crop".

```{r}
## crop to birds 
species = table(d_crop$valid_name)
species = species[which(species == 30)]
ex = names(species)

d_crop = dplyr::filter(d_crop, valid_name %in% ex)
d_crop = dplyr::filter(d_crop, valid_name != "Vireo olivaceus")
```

### Step 2: Data exploration

```{r}
# summarise data contents
dls = d_crop |>
  group_by(valid_name) |>
  group_split()

# check for basic population trends
mls = lapply(dls, function(x){lm(ABUNDANCE ~ YEAR, data = x)})

# extract slopes
coefs = mls |> lapply(coef) |> 
  bind_rows() |> 
  mutate("species" = unique(d_crop$valid_name))

# plot to see the slopes
ggplot(data = coefs) +
  geom_point(aes(y = species, x = YEAR))
```

### Step 3: Build a model for each species

```{r}
# check for basic population trends
gamls = lapply(dls, function(x){gam(ABUNDANCE ~ s(YEAR, k = 4), data = x)})
lapply(gamls, plot)
for(i in 1:length(gamls)){
  plot(gamls[[i]], main = dls[[i]]$valid_name[1])
}

# species to keep:
ex = ex[c(1,4,12,13,16,18,21,23,26,28)]
d_crop = dplyr::filter(d_crop, valid_name %in% ex)
```

### Step 4: Build an mvgam model for all species together

#### Prepare the data

```{r}
# format into long
dat = d_crop |>
  select(valid_name, ABUNDANCE, YEAR) |>
  rename("time" = "YEAR",
         "series" = "valid_name",
         "y" = "ABUNDANCE")
dat$y = as.vector(dat$y)
dat <- filter(dat, series != "Vireo olivaceus")
dat$series <- as.factor(dat$series)
dat$time <- as.integer(dat$time)-min(dat$time)


data_train = dat[which(d_crop$YEAR <= 1999),]
data_test = dat[which(d_crop$YEAR > 2000),]

ggplot(data = data_train) +
  geom_smooth(aes(x = time, y = y, 
                  col = series, fill = series),
              alpha = .1) +
  colorspace::scale_color_discrete_qualitative() +
  colorspace::scale_fill_discrete_qualitative() 
```

#### Prepare the priors

```{r}
npops = length(unique(data_train$series))
knots = 4

mvgam_prior <- mvgam(data = data_train,
                     formula = y ~
                       # global smoother for all pops over time
                       s(time, bs = "tp", k = knots) +
                       # random intercept per group
                       s(series, bs = 're', k = npops),
                     family = "poisson",
                     trend_model = 'GP',
                     chains = 3,
                     use_stan = TRUE,
                     prior_simulation = TRUE)

# record the priors
test_priors <- get_mvgam_priors(y ~
                                  # global smoother for all pops over time
                                  s(time, bs = "tp", k = knots) +
                                  # random intercept per group
                                  s(series, bs = 're', k = npops),
                                family = "poisson",
                                data = data_train,
                                trend_model = 'GP',
                                use_stan = TRUE)

# look at the priors
plot(mvgam_prior, type = 'smooths')
 
par(mfrow = c(6,5))
for(i in 1:ncol(Year_Geom_Means_all)){
  plot(mvgam_prior, type = 'trend', series = i)
}

plot(mvgam_prior, type = 're')
```

##### Check the number of knots

```{r}
knots = 4

hgam = mgcv::gam(y ~ s(time, bs = "tp", k = 5) + 
                         s(series, bs = 're', k = npops), 
                       family = "poisson",
                       data = data_train)
mgcv::gam.check(hgam)
plot(hgam)
```

#### Train the model on data

```{r}
#m1 <- mvgam(data = data_train,
              # formula =  y ~ s(time, bs = "tp", k = 5) + 
              #   s(series, bs = "re"),
              # use_lv = FALSE,
              # family = "poisson",
              # trend_model = 'GP',
              # use_stan = TRUE,
              # chains = 2, 
              # burnin = 5000,
              # samples = 10000)

#saveRDS(m1, paste0("variance/outputs/mvgam_variance.rds")) 
m1 = readRDS("variance/outputs/mvgam_variance.rds")
```

### Step 5: Plots and model outputs

#### Visualize model diagnostics and smooths

```{r}
plot(m1) # Basic model diagnostic plots

mvgam::plot_mvgam_smooth(m1) # Plot estimated smooth functions

mvgam::plot_mvgam_randomeffects(m1) # Plot random effects

dat$series |> unique() # List all unique series included in the dataset
```

#### Species associations

```{r}
sp_corr = mvgam::lv_correlations(m1) # Extract latent variable (species) correlation matrix

# clean up the species names 

colnames(sp_corr$mean_correlations) = gsub("_", " ", colnames(sp_corr$mean_correlations)) |> 
  stringr::str_to_sentence()
rownames(sp_corr$mean_correlations) = gsub("_", " ", rownames(sp_corr$mean_correlations)) |> 
  stringr::str_to_sentence()

```

#### Plot as a heatmap

Visualize and summarize species (latent variable) correlations from the model

```{r}
corrplot::corrplot(sp_corr$mean_correlations, 
                   type = "lower",
                   method = "color", 
                   tl.cex = 2.5, cl.cex = 3, tl.col = "black", font = 13)

sp_corr$mean_correlations |> mean()
sp_corr$mean_correlations |> sd()

sp_corr$mean_correlations |> apply(2, mean) 
sp_corr$mean_correlations |> apply(2, sd) |> lines()

sp_corr$mean_correlations |> hist()
```

## Box 3 - Prediction

### Step 1: Process the data

Here we use `d_crop`, previously processed in Box 2, and further prepare it for this section.

```{r}
# Add a rare/undersampled species for Example 1
d_crop_rare <- readRDS("prediction/example_rare_species.rds")

d_crop_merged <- rbind(d_crop, d_crop_rare)

# Rename columns and adjust abundance
dat <- d_crop_merged %>%
  rename(
    y = ABUNDANCE,
    series = valid_name, # for the mvgam requirement
    lat = LATITUDE,
    long = LONGITUDE,
    time = YEAR # for the mvgam requirement
  )

dat <- dat %>%
  group_by(time) %>%
  mutate(total_abun = sum(y)) %>%
  mutate(rel_abun = y / total_abun) %>%
  select(-total_abun)
```

#### `mvgam` format requirements

Prepare and format the dataset for HGAM fitting and forecasting: adjust columns to meet mvgam requirements, define training/testing subsets, and create datasets with and without specific species for out-of-sample forecasts.

```{r}
## Adjust columns for mvgam requirements
dat$y <- as.vector(dat$y)
dat <- filter(dat, series != "Vireo olivaceus")
dat$series <- as.factor(dat$series)
dat$time <- as.integer(dat$time) - min(dat$time)

# Subset the data in training and testing folds
data_train <- dat[which(d_crop$YEAR <= 1999), ]
data_test <- dat[which(d_crop$YEAR > 2000), ]

# subsetting the data with and without a species for out-of-sample forecasting
# Remove Setophaga pinus due to missing observations in some years

data_noMniotilta <- filter(dat, series != "Mniotilta varia" & series != "Setophaga pinus")
data_Mniotilta <- filter(dat, series == "Mniotilta varia")
```

### Step 2: Fit Models

#### Inspect and visualize training and testing data

Finalize and visualize data subsets: unused factor levels are removed, the temporal extent of the test set is verified, and all series are plotted to assess coverage between training and testing periods.

<https://github.com/eco4cast/Statistical-Methods-Seminar-Series/blob/main/clark-dynamic_gams/portal_example.R>

```{r}
set.seed(2505)

data_train <- data_train %>%
  droplevels()
data_test <- data_test %>%
  droplevels()

range(data_test$time)

# Plot series
plot_mvgam_series(
  data = data_train,
  newdata = data_test,
  series = "all"
)
```

#### Penalized splines forecast: `mod_forecast_ps`

A State-Space hierarchical GAM is fitted using a Poisson family, AR(1) temporal dynamics, and penalized spline smooths. The model structure incorporates hierarchical time effects for computational efficiency and summarizes key outputs excluding beta estimates.

```{r}
# Set up a State-Space hierarchical GAM with AR1 dynamics for autocorrelation
# Smooths are penalized splines
# mod_forecast_ps <- mvgam(
#   data = data_train,
#   formula = y ~
#     s(series, bs = "re"),
# 
#   # Hierarchical smooths of time set up as a
#   # State-Space model for sampling efficiency
#   trend_formula = ~
#     s(time, bs = "tp", k = 6) +
#       s(time, trend, bs = "sz", k = 6),
#   family = poisson(),
# 
#   # AR1 for "residual" autocorrelation
#   trend_model = AR(p = 1),
#   noncentred = TRUE,
#   priors = prior(exponential(2),
#     class = sigma
#   ),
#   backend = "cmdstanr"
# )

# Read the model
mod_forecast_ps <- readRDS("prediction/output/mod_forecast_ps.rds")
```

##### Model summary

```{r}
summary(mod_forecast_ps, include_betas = FALSE)
```

##### Plot the estimated smooth trends

```{r}
gratia::draw(mod_forecast_ps, trend_effects = TRUE)
conditional_effects(mod_forecast_ps)

forecast_penalized_splines <- plot_predictions(
  mod_forecast_ps,
  by = c("time", "series", "series"),
  newdata = datagrid(
    time = 1:max(data_test$time),
    series = unique
  ),
  type = "expected"
)
```

Obviously the splines show high extrapolation uncertainty into the test time points, but that is ok as it isn't the focus of this exercise. But if we wanted better forecasts, let's use GPs in place of the penalized smooths. <https://ecogambler.netlify.app/blog/autocorrelated-gams/>

##### Look at some of the AR1 estimates

```{r}
# Look at some of the AR1 estimates
mcmc_plot(mod_forecast_ps, variable = "ar1", regex = TRUE)
```

#### Gaussian process forecasts : `mod_forecast_GP`

This model replaces penalized spline smooths with Gaussian Process terms to more flexibly model temporal dependencies and enhance forecasting accuracy.

```{r}
# Using Gaussian Process in place of penalized smooths to get better forecasts
# mod_forecast_GP <- mvgam(
#   data = data_train,
#   formula = y ~
#     s(series, bs = "re"),
# 
#   # Hierarchical smooths of time set up as a
#   # State-Space model for sampling efficiency
#   trend_formula = ~
#     gp(time, k = 6) +
#       s(time, trend, bs = "sz", k = 6),
#   family = poisson(),
# 
#   # AR1 for "residual" autocorrelation
#   trend_model = AR(p = 1),
#   noncentred = TRUE,
#   priors = prior(exponential(2),
#     class = sigma
#   ),
#   backend = "cmdstanr"
# )

# Read the model
mod_forecast_GP <- readRDS("prediction/output/mod_forecast_GP.rds")
```

##### Model summary

```{r}
summary(mod_forecast_GP, include_betas = FALSE)
```

##### Predict

```{r}
# Build prediction grid
pred_data <- data.frame(
  time = rep(1:max(data_test$time), each = length(unique(data_train$series))),
  series = rep(unique(data_train$series), times = max(data_test$time))
)

# Get expected predictions by time and series
predictions <- predictions(
  mod_forecast_GP,
  newdata = pred_data,
  by = c("time", "series", "series"),
  type = "expected"
)
# Mark which points are forecasts & Add a vertical line where the train test splits (time = 22)
predictions$forecast <- ifelse(predictions$time > 22, "Forecast", "Fitted")
```

##### Plot species-level forecasts

```{r}
ggplot(predictions, aes(x = time, y = estimate)) +
  geom_ribbon(
    aes(ymin = conf.low, ymax = conf.high, fill = series),
    alpha = 0.2
  ) +
  geom_line(
    data = subset(predictions, forecast == "Fitted"),
    aes(color = series), linewidth = 1
  ) +
  geom_line(
    data = subset(predictions, forecast == "Forecast"),
    aes(color = series), linewidth = 1, linetype = "dashed"
  ) +
  geom_vline(xintercept = 22, linetype = "dotted") +
  geom_point(data = data_train, aes(x = time, y = y), alpha = 0.2) +
  geom_point(data = data_test, aes(x = time, y = y), alpha = 0.2) +
  facet_wrap(~series, scales = "free_y") +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 14, face = "italic")
  ) +
  labs(y = "Abundance", x = "Time") +
  theme(axis.title = element_text(size = 14))
```

##### Plot latent/global trend

```{r}
plot_predictions(
  mod_nick_GP,
  by = c("time"),
  newdata = datagrid(
    time = 1:max(data_test$time),
    series = unique
  ),
  type = "expected"
) +
  geom_vline(xintercept = 22, linetype = "dotted") +
  labs(y = "Global latent trend", x = "Time") +
  theme(axis.title = element_text(size = 14))
```

### Step 3: Gaussian process - predicting new species

#### Black-and-white Warbler (BAWW) Post-stratification model

##### Training dataset & train the model 

In this section, we prepare a training dataset that excludes *Mniotilta varia* (Black-and-white Warbler) to perform post-stratification. We examine missing observations across species and time, verify data completeness, and then load the fitted state-space HGAM (Gaussian Process–based) trained on the reduced dataset.

```{r}
# Black-and-white Warbler Post-stratification Model ----
# Create training data excluding Mniotilta varia (Black-and-white Warbler)
data_train_noBAWW <- data_noMniotilta %>%
  droplevels()

# Set up State-Space hierarchical GAM excluding BAWW for post-stratification
set.seed(2505)
data_train_noBAWW %>%
  group_by(series) %>%
  summarise(
    n_obs = n(),
    expected_obs = length(unique(data_train_noBAWW$time)),
    missing_obs = expected_obs - n_obs
  ) %>%
  filter(missing_obs > 0)
unique(data_train_noBAWW$series)


colSums(is.na(data_train_noBAWW))

# mod_strat_BAWW <- mvgam(
#   data = data_train_noBAWW,
#   formula = y ~
#     s(series, bs = "re"),
# 
#   # Hierarchical smooths of time set up as a
#   # State-Space model for sampling efficiency
#   trend_formula = ~
#     gp(time, k = 3, gr = FALSE),
#   family = poisson(),
# 
#   # AR1 for "residual" autocorrelation
#   trend_model = AR(p = 1),
#   noncentred = TRUE,
#   priors = prior(exponential(2),
#     class = sigma
#   ),
#   backend = "cmdstanr"
# )

# Read the model
mod_strat_BAWW <- readRDS("prediction/output/mod_strat_BAWW_GP_all_years.rds")
```

##### Construct weighted prediction data for post-stratification

```{r}
# Post-stratification for Black-and-white Warbler prediction ----
# predict trends for all species and weight these based
# on their "distance" to the new species
unique_species_noBAWW <- levels(data_train_noBAWW$series)

# Add some weights; here a higher value means that species is "closer" to the
# un-modelled target species. This could for example be the inverse of a phylogenetic
# or functional distance metric

# Initialize all weights to 1
species_weights_BAWW <- rep(1, length(unique_species_noBAWW))
names(species_weights_BAWW) <- unique_species_noBAWW

# Assign higher weight to warblers species
# Weight it 10x higher than other species for strong post-stratification

setophaga_species <- grep("Setophaga", unique_species_noBAWW, value = TRUE)
species_weights_BAWW[setophaga_species] <- 10
species_weights_BAWW["Seiurus aurocapilla"] <- 10


# Generate the prediction grid; here we replicate each species' temporal grid
# a number of times, with the number of replications determined by the weight
# vector above
pred_dat_BAWW <- do.call(
  rbind,
  lapply(seq_along(unique_species_noBAWW), function(sp) {
    sp_name <- unique_species_noBAWW[sp]
    weight <- species_weights_BAWW[sp_name]

    do.call(
      rbind,
      replicate(
        weight,
        data.frame(
          time =
            1:max(data_train_noBAWW$time + 1), # time is indexed starting at 0
          series = sp_name
        ),
        simplify = FALSE
      )
    )
  })
) %>%
  dplyr::mutate(
    series = factor(series, levels = levels(data_train_noBAWW$series))
  )
```

##### Get post-stratified predictions 

```{r}
# Generate post-stratified predictions for Black-and-white Warbler
# Marginalize over "time" to compute weighted average predictions
post_strat_BAWW <- marginaleffects::avg_predictions(
  mod_strat_BAWW,
  newdata = pred_dat_BAWW,
  by = "time",
  type = "expected"
)
```

##### Visualize post-stratified predictions for BAWW

We compare the post-stratified predictions for *Mniotilta varia* (Black-and-white Warbler) with the observed abundance data from the original dataset. The plot displays the predicted trend with 95% credible intervals (shaded area) alongside the empirical observations, allowing for a visual assessment of how well the post-stratified model captures the species’ temporal dynamics.

```{r}
# Visualization: Post-stratified BAWW predictions ----
# Plot the post-stratified trend predictions for Black-and-white Warbler
# Compare with actual BAWW data from the original dataset
actual_BAWW_data <- dat %>%
  filter(series == "Mniotilta varia")

plot_BAWW_poststrat <- ggplot(post_strat_BAWW, aes(x = time, y = estimate)) +
  geom_ribbon(aes(ymax = conf.high, ymin = conf.low),
    colour = NA, fill = "steelblue", alpha = 0.4
  ) +
  geom_line(colour = "steelblue", linewidth = 1.2) +
  geom_point(
    data = actual_BAWW_data,
    aes(x = time, y = y),
    colour = "black", alpha = 0.7, size = 2
  ) +
  theme_classic() +
  labs(
    y = "Abundance (Black-and-white Warbler)",
    x = "Time"
  ) +
  theme(
    plot.title = element_text(size = 12),
    plot.subtitle = element_text(size = 10)
  )

print(plot_BAWW_poststrat)
```

##### Anchor and evaluate Post-stratified predictions for BAWW model

To align the post-stratified forecasts with observed data, we anchor the predictions by calibrating the intercept using the first year of *Mniotilta varia* (Black-and-white Warbler) observations. The offset ensures that predicted abundances match the empirical baseline. We then assess model performance using MAE and RMSE, and compare prediction agreement with a standard GAM by examining correlation and directional trend consistency between the two models.

```{r}
# Anchored Post-stratified BAWW Model ----
# Use first year of BAWW data to calibrate the intercept of post-stratified predictions

# Get the first year BAWW observation for anchoring
first_year_BAWW <- actual_BAWW_data %>%
  filter(time == 0)

# Find the post-stratified prediction for the same time point
first_year_pred <- post_strat_BAWW %>%
  filter(time == 1)

# Calculate the offset needed to match observed abundance
abundance_offset <- first_year_BAWW$y - first_year_pred$estimate

# Apply offset to all post-stratified predictions
post_strat_BAWW_anchored <- post_strat_BAWW %>%
  mutate(
    estimate_original = estimate,
    conf.low_original = conf.low,
    conf.high_original = conf.high,
    estimate = estimate + abundance_offset,
    conf.low = conf.low + abundance_offset,
    conf.high = conf.high + abundance_offset
  )

mvgam_pred_mean <- post_strat_BAWW_anchored$estimate
mae_mvgam <- mean(abs(data_Mniotilta$y - mvgam_pred_mean))
rmse_mvgam <- sqrt(mean((data_Mniotilta$y - mvgam_pred_mean)^2))


# GAM for BAWW
BAWW_gam <- gam(y ~ s(time), data = data_Mniotilta)


# Calculate correlation between predictions
cor_predictions <- cor(mvgam_pred_mean, gam_pred)
cor_predictions

# Direction of trend agreement
gam_trend_direction <- sign(diff(gam_pred))
mvgam_trend_direction <- sign(diff(mvgam_pred_mean))
trend_agreement <- mean(gam_trend_direction == mvgam_trend_direction)
trend_agreement
```

##### Visualize anchored versus original post-stratified predictions

This plot compares the anchored post-stratified predictions for *Mniotilta varia* (Black-and-white Warbler) with the observed abundance data. The anchored model, shown with a dashed green line and shaded credible interval, represents predictions adjusted to match the observed baseline, allowing visual assessment of the calibration effect relative to the original post-stratified estimates.

```{r}
# Visualization: Anchored vs Original Post-stratified Predictions ----
plot_BAWW_anchored <- ggplot() +
  # Anchored post-stratified prediction
  geom_ribbon(
    data = post_strat_BAWW_anchored,
    aes(x = time, ymin = conf.low, ymax = conf.high),
    fill = "darkgreen", alpha = 0.4
  ) +
  geom_line(
    data = post_strat_BAWW_anchored,
    aes(x = time, y = estimate),
    color = "darkgreen", size = 1.2, linetype = "dashed"
  ) +

  # Actual BAWW data
  geom_point(
    data = actual_BAWW_data,
    aes(x = time, y = y),
    colour = "black", alpha = 0.2, size = 2.5
  ) +
  theme_classic() +
  labs(
    y =
      expression(paste("Predicted ", italic("Mniotilta varia"), " abundance")),
    x = "Time"
  ) +
  theme(
    axis.title = element_text(size = 12),
    legend.position = "none"
  )
```

# References

Pardieck, K. L., Ziolkowski Jr., D. J., and Hudson, M. A. R. (2015). North American Breeding Bird Survey Dataset 1966 - 2014, version 2014.0. https://biotime.st-andrews.ac.uk/selectStudy.php?study=195

Pedersen, E. J., Miller, D. L., Simpson, G. L., & Ross, N. (2019). Hierarchical generalized additive models in ecology: an introduction with mgcv. PeerJ, 7, e6876.

Pedersen, E. J., Koen-Alonso, M., & Tunney, T. D. (2020). Detecting regime shifts in communities using estimated rates of change. ICES Journal of Marine Science, 77(4), 1546-1555
